{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuobinxiong/CS789/blob/main/Lab2_Evasion_Attack_CNN_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1IIenRzV7Gv"
      },
      "source": [
        "# Attacking a CNN\n",
        "\n",
        "The CNN is vunerable to adversarial examples as ![adv example](https://www.tensorflow.org/tutorials/generative/images/adversarial_example.png)\n",
        "\n",
        "In this exercise we will train a CNN to distinguish between instances of handwritten `0` and instances of handwritten `1`. We will be using `PyTorch` to do this.  \n",
        "\n",
        "Once we have a trained classifier, we will create adversarial examples from scratch using `ART`\n",
        "\n",
        "This is adopted from https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:17:58.581831Z",
          "start_time": "2021-09-20T18:17:58.530114Z"
        },
        "id": "_BEmxB6BOawB"
      },
      "outputs": [],
      "source": [
        "# some configurations for jupyter notebook\n",
        "%config Completer.use_jedi = False\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:18:00.584863Z",
          "start_time": "2021-09-20T18:17:59.308424Z"
        },
        "id": "nhoEjgYmWJ0E",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:18:05.331321Z",
          "start_time": "2021-09-20T18:18:04.318186Z"
        },
        "id": "iIH4d-w4V7G7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIL2ziyzV7G_"
      },
      "source": [
        "The MNIST dataset contains data for all of the digits.\n",
        "\n",
        "We need to normalize the data. Here, we use the API from `ART`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3nYU03lV7HD"
      },
      "source": [
        "Load the actual data. It will load the data as numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:18:08.140320Z",
          "start_time": "2021-09-20T18:18:07.099854Z"
        },
        "id": "CMKzVNfRV7HA"
      },
      "outputs": [],
      "source": [
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:39:44.338855Z",
          "start_time": "2021-09-20T18:39:43.231914Z"
        },
        "id": "PGJqi9ncOawJ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# print(x_train.shape,x_test.shape)\n",
        "# Step 1a: Swap axes to PyTorch's NCHW format\n",
        "x_train = np.transpose(...).astype(np.float32)\n",
        "x_test = np.transpose(...).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:39:44.365959Z",
          "start_time": "2021-09-20T18:39:44.341398Z"
        },
        "id": "w-dbdU9WOawK"
      },
      "outputs": [],
      "source": [
        "print(type(x_train))\n",
        "print(x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d64xNkKdV7HX"
      },
      "source": [
        "We are using a very simple CNN. This network can be used to distinguish between all 10 classes with very high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:39:44.535674Z",
          "start_time": "2021-09-20T18:39:44.368150Z"
        },
        "id": "GMjW64ADV7HY"
      },
      "outputs": [],
      "source": [
        "# define the classifier\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
        "        self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
        "        self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8rGWZ-OawN"
      },
      "source": [
        "Then, we initialize a model and train with the cross-entropy loss.\n",
        "\n",
        "To simplify the training code, we use the wrapper `PyTorchClassifier` from `ART` to train the model.\n",
        "\n",
        "https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/attacks/evasion.html#fast-gradient-method-fgm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:39:55.972521Z",
          "start_time": "2021-09-20T18:39:44.539201Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iZ-HomzOawN",
        "outputId": "0e33e0ae-5ce9-40d8-dde5-0e862ed31798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on benign test examples: 98.15%\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Create the model\n",
        "model = ...\n",
        "\n",
        "# Step 2a: Define the loss function and the optimizer\n",
        "criterion = ...\n",
        "optimizer = ...\n",
        "\n",
        "# Step 3: Create the ART classifier\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer,\n",
        "    input_shape=(1, 28, 28),\n",
        "    nb_classes=10,\n",
        ")\n",
        "\n",
        "# Step 4: Train the ART classifier\n",
        "classifier.fit(...)\n",
        "\n",
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "predictions = ...\n",
        "accuracy = ...\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:39:56.005178Z",
          "start_time": "2021-09-20T18:39:55.975174Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zr9bUY7iOawP"
      },
      "outputs": [],
      "source": [
        "# the device(cpu/gpu) of the model\n",
        "device = next(model.parameters()).device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn0dNIotIQ_n"
      },
      "source": [
        "Let's get to the actual attack. First, we pick a sample that we want to perturb. After that we will be implementing our own FGSM attack.\n",
        "\n",
        "The attack is fairly simple. It consists of the following steps:\n",
        "\n",
        "1.   Compute the loss of the original sample\n",
        "2.   Calculate the gradient of the loss w.r.t the input\n",
        "3.   Take the sign of the gradient and add a fraction episilon to the input, namely $x + \\epsilon sign(\\nabla_x J(x, y))$\n",
        "\n",
        "Epsilon controlls the strenght of the pertubation.\n",
        "\n",
        "First, we select a sample to visualize it and output the model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:44:22.767406Z",
          "start_time": "2021-09-20T18:44:22.433939Z"
        },
        "id": "-1U3SGAeOawQ"
      },
      "outputs": [],
      "source": [
        "#chose a sample to pertubrate\n",
        "sample_ind = 25 # chosen by totaly random dice roll\n",
        "# picking a test sample\n",
        "sample = x_test[ sample_ind, : ]\n",
        "print( sample.shape )\n",
        "# plot the first instance in the traning set\n",
        "plt.imshow( sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n",
        "# check the prediction performance\n",
        "t_sample = torch.FloatTensor(sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ).to(device)\n",
        "pred_prob = F.softmax(...)\n",
        "logits = classifier.predict( ... )\n",
        "\n",
        "print( 'output for the test samples:\\n', logits )\n",
        "print( 'class prediction for the test samples:\\n', pred_prob.detach() )\n",
        "print( 'predicted as', np.argmax( ... ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSDRK1zAOawS"
      },
      "source": [
        "Since `ART` loads data as numpy array, we create a variable as PyTorch Tensor for convenience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ke00x9-OawT"
      },
      "source": [
        "Construct adversarial examples from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUDoLLIKOawU"
      },
      "source": [
        "It's caused by the mechanism of PyTorch.\n",
        "\n",
        "By default, only model's parameters will compute/require gradients.\n",
        "\n",
        "Now, we need to let the input data require gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:44:59.675502Z",
          "start_time": "2021-09-20T18:44:58.371025Z"
        },
        "id": "RovKr9sKIQgh"
      },
      "outputs": [],
      "source": [
        "t_sample = torch.FloatTensor(sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ).to(device)\n",
        "one_hot_y = torch.LongTensor( y_test[ sample_ind, : ].reshape( ( 1, -1 ) ) ).to(device)\n",
        "t_y = torch.argmax(one_hot_y, dim=1)\n",
        "\n",
        "# constructing adversarial examples\n",
        "eps = 0.1 # allowed maximum modification\n",
        "\n",
        "# Set the data require gradients\n",
        "t_sample.requires_grad = True\n",
        "\n",
        "# compute logits\n",
        "logits = ...\n",
        "\n",
        "# compute the loss of our original sample\n",
        "loss = ...\n",
        "\n",
        "# get the gradient wrt to the input.\n",
        "grads = ...\n",
        "\n",
        "# calculate the pertubation\n",
        "perturbation = ...\n",
        "\n",
        "# apply pertubation\n",
        "x_adv = ...\n",
        "\n",
        "# now that we have the adversarial examples\n",
        "# get the prediction result and print the adversarial example\n",
        "\n",
        "print( 'our adversarial example' )\n",
        "print( x_adv.shape )\n",
        "print( 'logits for our sample: \\t\\n', classifier.predict( x_adv.cpu().detach().numpy() ) )\n",
        "print( 'class prediction for our sample: \\t\\n', F.softmax( model( x_adv ), dim=1 ).detach()  )\n",
        "print( 'predicted as', np.argmax( classifier.predict( x_adv.cpu().detach().numpy() ) , axis=1) )\n",
        "plt.imshow( x_adv.cpu().detach().numpy().reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azepEwpTewML"
      },
      "source": [
        "The FGSM is one of the most simple attacks.\n",
        "As we can see, results are not very convincing since the perturbation is perceptible.\n",
        "We can improve on it by making it iterative.\n",
        "\n",
        "Using the code from above, create an iterative version of FGSM that calculates a new perturbation for ever iteration and stops once it achieve misclassifaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:46:29.491425Z",
          "start_time": "2021-09-20T18:46:29.331852Z"
        },
        "id": "mOHo8eQ0gS4F"
      },
      "outputs": [],
      "source": [
        "epsilon = 0.005\n",
        "iterations = 10\n",
        "x_adv = t_sample.detach().clone()\n",
        "x_adv.requires_grad = True\n",
        "\n",
        "# Write an iteration version of FSGM\n",
        "for i in range(iterations):\n",
        "  logits = ...\n",
        "  loss = ...\n",
        "  grads = ...\n",
        "  perturbation = ...\n",
        "  x_adv = ...\n",
        "\n",
        "print( 'our adversarial example' )\n",
        "print( x_adv.shape )\n",
        "print( 'logits for our sample: \\t\\n', classifier.predict( x_adv.cpu().detach().numpy() ) )\n",
        "print( 'class prediction for our sample: \\t\\n', F.softmax( model( x_adv ), dim=1 ).detach()  )\n",
        "print( 'predicted as', np.argmax( classifier.predict( x_adv.cpu().detach().numpy() ) , axis=1) )\n",
        "plt.imshow( x_adv.cpu().detach().numpy().reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VszDZ1p6V7Hc"
      },
      "source": [
        "Let's use `ART` library to do the actual attack.\n",
        "\n",
        "https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/attacks/evasion.html#fast-gradient-method-fgm\n",
        "\n",
        "We will also use the FGSM attack to generate an adversarial example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:46:40.358884Z",
          "start_time": "2021-09-20T18:46:37.843558Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQymSykoOawd",
        "outputId": "fe63a2d9-25b6-4be3-c302-fa63763be32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on clean test examples: 98.15%\n",
            "Accuracy on adversarial test examples: 25.5%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "predictions = ...\n",
        "accuracy = ...\n",
        "print(\"Accuracy on clean test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "attack = FastGradientMethod(...)\n",
        "x_test_adv = attack.generate(...)\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "predictions = ...\n",
        "accuracy = ...\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:47:11.028811Z",
          "start_time": "2021-09-20T18:47:10.899485Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wCdGoCVDOawe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "bfb8c048-5896-4cff-decb-dd4353cb3431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits for our sample: \t\n",
            " [[-4.5948973  -7.5844593  -8.818335   -3.101173   -5.1429076   6.2654834\n",
            "   4.299975   -2.0210223  -0.90931743 -3.8383381 ]]\n",
            "predicted as [5]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualize one example\n",
        "x_test_adv = ...\n",
        "print( 'logits for our sample: \\t\\n', ...)\n",
        "print( 'predicted as', ... )\n",
        "plt.imshow( x_test_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8212TwiOOawf"
      },
      "source": [
        "You can see that it's much simpler than we write it from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrPLNrpgOawf"
      },
      "source": [
        "You can check it from https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJQIF24Y91W"
      },
      "source": [
        "We have seen that FGSM does not do a great job of producing adversarial examples when work with 0 and 1. Update the code above work on all 10 digits and try for a number of 0 instance what class they get transformed into in an untargeted attack.\n",
        "Alternativley pick a pair of numbers that you think are closer to each orther and the FGSM attack should work better with.\n",
        "\n",
        "\n",
        "`ART` provides more attacks than the once introduced above. Try any other attacks from the official documents.\n",
        "\n",
        "You can find more information on the attacks here: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Attacks and https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/attacks/evasion.html#projected-gradient-descent-pgd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "# Evaluate\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on clean test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "from art.attacks.evasion import #A method name\n",
        "# generate attack samples\n",
        "attack =\n",
        "x_test_adv =\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions =\n",
        "accuracy =\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Visualize one example\n",
        "x_test_adv = attack.generate(x=x_test[sample_ind:sample_ind+1, ])\n",
        "print( 'logits for our sample: \\t\\n', classifier.predict( x_test_adv ) )\n",
        "# print( 'class prediction for our sample: \\t\\n', F.softmax( model( x_test_adv ), dim=1 ).detach()  )\n",
        "print( 'predicted as', np.argmax( classifier.predict( x_test_adv ) , axis=1) )\n",
        "\n",
        "plt.imshow( x_test_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "metadata": {
        "id": "Os5W-kbNQ8fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Step: Transferability\n",
        "1. you have two attacks\n",
        "2. use adv samples generated from one attack to evade the other\n",
        "---\n",
        "1. train another model\n",
        "2. use the first model's adv example to attack the second model"
      ],
      "metadata": {
        "id": "3NMJ5gDVRXvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  your code here"
      ],
      "metadata": {
        "id": "9vUs_F_PRW-T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}